{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# X-Learner for Conditional Average Treatment Effect (CATE) Estimation\n",
    "\n",
    "This notebook demonstrates the use of X-Learner for estimating heterogeneous treatment effects. \n",
    "\n",
    "## What is X-Learner?\n",
    "\n",
    "X-Learner (Crossover-Learner) is a meta-learner approach for estimating Conditional Average Treatment Effects (CATE). The key characteristics of X-Learner are:\n",
    "\n",
    "1. **Multi-Stage Approach**: Uses a multi-stage estimation process\n",
    "2. **Separate Models**: Fits separate models for control and treatment groups\n",
    "3. **Crossover Estimation**: Estimates treatment effects by crossing over between groups\n",
    "4. **Flexible Base Learners**: Can use any regression model that follows scikit-learn's API\n",
    "5. **Robust to Imbalance**: Performs well when treatment and control groups have different sizes\n",
    "\n",
    "## How X-Learner Works\n",
    "\n",
    "The X-Learner approach follows these steps:\n",
    "1. Fit separate outcome models for treatment and control groups\n",
    "2. Predict counterfactual outcomes for each individual\n",
    "3. Compute \"imputed\" treatment effects for each individual\n",
    "4. Train models to predict these imputed treatment effects\n",
    "5. Combine predictions to get the final CATE estimate\n",
    "\n",
    "The main advantage of X-Learner is its ability to handle imbalanced treatment and control groups effectively. It often outperforms other meta-learners when treatment groups are imbalanced and provides more stable estimates in many practical scenarios.\n",
    "</div>\n"
   ],
   "id": "9065d0f0e5e27924"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# Library Imports\n",
    "\n",
    "We import the necessary libraries for this demonstration:\n",
    "\n",
    "- **synthetic_data_for_cate2**: Custom module for generating synthetic data with enhanced heterogeneity for treatment effects\n",
    "- **XLearner**: Our implementation of the X-Learner meta-learner\n",
    "- **sklearn models**: Various regression models to use as base learners\n",
    "- **matplotlib/seaborn**: For visualization\n",
    "- **numpy**: For numerical operations\n",
    "\n",
    "We also attempt to import optional dependencies (LightGBM and XGBoost) which provide additional base learners.\n",
    "</div>\n"
   ],
   "id": "effd67409409e8ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T02:39:15.847759Z",
     "start_time": "2025-06-15T02:39:15.830097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from synthetic_data.synthetic_data_for_cate_class import synthetic_data_for_cate\n",
    "from metalearners.x_learner import XLearner\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Set plot style\n",
    "try:\n",
    "    # For newer matplotlib versions (>=3.6)\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "except ValueError:\n",
    "    # For older matplotlib versions\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "# Try to import optional dependencies\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "    LIGHTGBM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LIGHTGBM_AVAILABLE = False\n",
    "    print(\"LightGBM not available. Some examples will be skipped.\")\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"XGBoost not available. Some examples will be skipped.\")\n"
   ],
   "id": "513bccc86779224c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# Note on Dependencies\n",
    "\n",
    "This notebook requires the following packages:\n",
    "- numpy, matplotlib, seaborn: For data manipulation and visualization\n",
    "- scikit-learn: For machine learning models\n",
    "- lightgbm, xgboost (optional): For gradient boosting models\n",
    "\n",
    "The notebook also uses local packages:\n",
    "- synthetic_data.synthetic_data_for_cate2: For generating synthetic data with enhanced heterogeneity\n",
    "- metalearners.x_learner: For the XLearner implementation\n",
    "\n",
    "Make sure you have installed all required dependencies before running this notebook.\n",
    "</div>\n"
   ],
   "id": "6d0e106b5da3d820"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# Synthetic Data Generation\n",
    "\n",
    "We generate synthetic data with known heterogeneous treatment effects using the `generate_synthetic_data_for_cate2()` function. This function creates:\n",
    "\n",
    "- A feature matrix with 5 covariates (by default)\n",
    "- A binary treatment indicator (1=treated, 0=control)\n",
    "- An outcome variable that depends on both covariates and treatment\n",
    "\n",
    "The data generation process includes:\n",
    "- Non-linear confounding (treatment assignment depends on X1 and X2)\n",
    "- Heterogeneous treatment effects (effects vary based on all covariates)\n",
    "- Non-linear baseline effects (outcome depends non-linearly on covariates)\n",
    "- Heteroskedastic noise (noise level varies with X1)\n",
    "\n",
    "This synthetic data allows us to evaluate the performance of different CATE estimation methods, as we know the true treatment effects.\n",
    "</div>\n"
   ],
   "id": "29b9030d60db5b3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T02:39:15.861721Z",
     "start_time": "2025-06-15T02:39:15.855418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create an instance of synthetic_data_for_cate with model2\n",
    "data_generator = synthetic_data_for_cate(model_type='model2')\n",
    "\n",
    "# Generate synthetic data with heterogeneous treatment effects\n",
    "features, treatment_vector, outcomes = data_generator.get_synthetic_data()\n",
    "\n",
    "# Print basic information about the generated data\n",
    "print(f\"Generated data with {features.shape[0]} samples and {features.shape[1]} features\")\n",
    "print(f\"Treatment assignment rate: {treatment_vector.mean():.2f}\")\n",
    "print(f\"Outcome mean: {outcomes.mean():.2f}\")\n"
   ],
   "id": "cf580f94af927d04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# Model Initialization and Fitting\n",
    "\n",
    "We initialize several X-Learner models with different base learners:\n",
    "\n",
    "1. **Random Forest**: A non-parametric model that can capture complex non-linear relationships\n",
    "2. **Linear Regression**: A simple parametric model that assumes linear relationships\n",
    "3. **LightGBM** (if available): A gradient boosting framework that uses tree-based learning\n",
    "4. **XGBoost** (if available): Another gradient boosting framework with different implementation\n",
    "\n",
    "Each model has different strengths and weaknesses for CATE estimation. For this demonstration, we'll use the Random Forest-based X-Learner as our primary model.\n",
    "\n",
    "The fitting process involves:\n",
    "1. Fitting separate models for control and treatment groups\n",
    "2. Predicting counterfactual outcomes for each group\n",
    "3. Computing individual treatment effects\n",
    "4. Training models to predict these treatment effects\n",
    "</div>\n"
   ],
   "id": "fdb47d9817d6c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# Base Learners for X-Learner: Principles, Pros, and Cons\n",
    "\n",
    "The choice of base learner significantly impacts the performance of X-Learner for CATE estimation. Here we describe the basic ideas, advantages, and limitations of each base learner.\n",
    "\n",
    "## RandomForestRegressor\n",
    "\n",
    "### Basic Principles\n",
    "- **Ensemble Method**: Combines multiple decision trees to improve prediction accuracy and control overfitting\n",
    "- **Bootstrap Aggregating (Bagging)**: Each tree is trained on a random subset of the data with replacement\n",
    "- **Feature Randomization**: At each split, only a random subset of features is considered\n",
    "- **Averaging**: Final prediction is the average of predictions from all trees\n",
    "\n",
    "### Pros for CATE Estimation\n",
    "- **Captures Non-linear Relationships**: Can model complex, non-linear treatment effects without explicit specification\n",
    "- **Handles Interactions**: Automatically captures interactions between treatment and covariates\n",
    "- **Robust to Outliers**: Less sensitive to extreme values in the data\n",
    "- **No Distributional Assumptions**: Does not assume normality or homoscedasticity\n",
    "- **Feature Importance**: Provides insights into which covariates drive treatment effect heterogeneity\n",
    "\n",
    "### Cons for CATE Estimation\n",
    "- **Black Box**: Less interpretable than linear models\n",
    "- **Treatment Variable Importance**: May not give sufficient importance to the treatment indicator\n",
    "- **Computational Cost**: Training many trees can be computationally intensive\n",
    "- **Hyperparameter Sensitivity**: Performance depends on proper tuning of hyperparameters\n",
    "- **Extrapolation Limitations**: May not extrapolate well to regions with sparse data\n",
    "\n",
    "## LGBMRegressor (LightGBM)\n",
    "\n",
    "### Basic Principles\n",
    "- **Gradient Boosting Framework**: Builds trees sequentially, with each tree correcting errors of previous trees\n",
    "- **Leaf-wise Growth**: Grows trees by leaf-wise (best-first) rather than level-wise growth\n",
    "- **Histogram-based Learning**: Buckets continuous features into discrete bins to speed up training\n",
    "- **Gradient-based One-Side Sampling (GOSS)**: Focuses on instances with larger gradients during training\n",
    "\n",
    "### Pros for CATE Estimation\n",
    "- **High Performance**: Often achieves state-of-the-art prediction accuracy\n",
    "- **Efficiency**: Faster training speed and lower memory usage than traditional gradient boosting\n",
    "- **Handles Large Datasets**: Scales well to datasets with many observations\n",
    "- **Regularization Options**: Built-in L1/L2 regularization to prevent overfitting\n",
    "- **Categorical Feature Support**: Native handling of categorical variables\n",
    "\n",
    "### Cons for CATE Estimation\n",
    "- **Complex Tuning**: Requires careful hyperparameter tuning for optimal performance\n",
    "- **Overfitting Risk**: Can overfit on small datasets without proper regularization\n",
    "- **Less Robust to Noisy Data**: May be more sensitive to noise than Random Forests\n",
    "- **Treatment Importance**: Like Random Forests, may not give sufficient importance to treatment indicator\n",
    "- **Installation Challenges**: Requires additional system dependencies\n",
    "\n",
    "## XGBRegressor (XGBoost)\n",
    "\n",
    "### Basic Principles\n",
    "- **Extreme Gradient Boosting**: Enhanced implementation of gradient boosting\n",
    "- **Regularized Learning**: Includes L1 and L2 regularization terms in the objective function\n",
    "- **Approximate Greedy Algorithm**: Uses a quantile sketch algorithm to find approximate best splits\n",
    "- **Sparsity-Aware Split Finding**: Efficiently handles missing values and sparse data\n",
    "\n",
    "### Pros for CATE Estimation\n",
    "- **Prediction Accuracy**: Consistently strong performance across many prediction tasks\n",
    "- **Regularization**: Built-in mechanisms to prevent overfitting\n",
    "- **Handles Missing Values**: Native support for missing data\n",
    "- **Parallel Processing**: Efficient computation using multi-threading\n",
    "- **Cross-validation**: Built-in cross-validation capabilities\n",
    "\n",
    "### Cons for CATE Estimation\n",
    "- **Complexity**: Many hyperparameters to tune\n",
    "- **Black Box Nature**: Limited interpretability of the model\n",
    "- **Memory Usage**: Can be memory-intensive for large datasets\n",
    "- **Treatment Variable Importance**: May not prioritize treatment indicator appropriately\n",
    "- **Installation Requirements**: Depends on additional libraries\n",
    "\n",
    "## LinearRegression\n",
    "\n",
    "### Basic Principles\n",
    "- **Linear Function**: Models outcome as a weighted sum of input features\n",
    "- **Ordinary Least Squares (OLS)**: Minimizes the sum of squared differences between observed and predicted values\n",
    "- **Closed-form Solution**: Parameters can be calculated directly without iterative optimization\n",
    "- **Additive Effects**: Assumes features contribute independently to the outcome\n",
    "\n",
    "### Pros for CATE Estimation\n",
    "- **Interpretability**: Clear interpretation of coefficients, including treatment effect\n",
    "- **Treatment Interaction Modeling**: Can explicitly model interactions between treatment and covariates\n",
    "- **Computational Efficiency**: Fast to train and make predictions\n",
    "- **Stability**: Results are stable and reproducible\n",
    "- **Statistical Inference**: Provides p-values and confidence intervals for treatment effects\n",
    "\n",
    "### Cons for CATE Estimation\n",
    "- **Linearity Assumption**: Cannot capture non-linear treatment effects without manual feature engineering\n",
    "- **Homogeneity Assumption**: Assumes constant error variance across all observations\n",
    "- **Sensitivity to Outliers**: Outliers can significantly impact coefficient estimates\n",
    "- **Limited Flexibility**: May underfit complex relationships in the data\n",
    "- **Collinearity Issues**: Performance degrades with highly correlated features\n",
    "\n",
    "## Choosing the Right Base Learner\n",
    "\n",
    "The optimal base learner depends on your specific use case:\n",
    "\n",
    "- **RandomForestRegressor**: Good default choice that balances flexibility and robustness\n",
    "- **LGBMRegressor/XGBRegressor**: Best for large datasets where prediction accuracy is paramount\n",
    "- **LinearRegression**: Ideal when interpretability is critical or when the treatment effect is known to be linear\n",
    "\n",
    "For complex, heterogeneous treatment effects, tree-based methods (Random Forest, LightGBM, XGBoost) typically outperform linear models. However, linear models offer better interpretability and explicit modeling of treatment interactions.\n",
    "</div>\n"
   ],
   "id": "38c9bbf0b2c6e660"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T02:39:16.469417Z",
     "start_time": "2025-06-15T02:39:15.888440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize X-Learner with different base models\n",
    "x_learner_rf = XLearner(RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "x_learner_linear = XLearner(LinearRegression())\n",
    "\n",
    "# Create LightGBM model if available\n",
    "if 'LIGHTGBM_AVAILABLE' in globals() and LIGHTGBM_AVAILABLE:\n",
    "    x_learner_lgbm = XLearner(LGBMRegressor(random_state=42))\n",
    "    # Uncomment to use LightGBM model\n",
    "    # xl = x_learner_lgbm\n",
    "\n",
    "# Create XGBoost model if available\n",
    "if 'XGBOOST_AVAILABLE' in globals() and XGBOOST_AVAILABLE:\n",
    "    x_learner_xgb = XLearner(XGBRegressor(random_state=42))\n",
    "    # Uncomment to use XGBoost model\n",
    "    # xl = x_learner_xgb\n",
    "\n",
    "# Select Random Forest as our primary model\n",
    "xl = x_learner_rf\n",
    "\n",
    "# Generate synthetic data with heterogeneous treatment effects if not already defined\n",
    "if 'features' not in globals():\n",
    "    # Create an instance of synthetic_data_for_cate with model2\n",
    "    data_generator = synthetic_data_for_cate(model_type='model2')\n",
    "\n",
    "    # Generate synthetic data\n",
    "    features, treatment_vector, outcomes = data_generator.get_synthetic_data()\n",
    "    print(f\"Generated data with {features.shape[0]} samples and {features.shape[1]} features\")\n",
    "    print(f\"Treatment assignment rate: {treatment_vector.mean():.2f}\")\n",
    "    print(f\"Outcome mean: {outcomes.mean():.2f}\")\n",
    "else:\n",
    "    # If features already exist, create a data generator to calculate true CATE\n",
    "    data_generator = synthetic_data_for_cate(model_type='model2')\n",
    "\n",
    "# Fit the model\n",
    "print(\"Fitting X-Learner with Random Forest...\")\n",
    "xl.fit(\n",
    "    X=features,             # Feature matrix\n",
    "    y=outcomes,             # Observed outcomes\n",
    "    treatment=treatment_vector      # Treatment assignments (0/1)\n",
    ")\n",
    "print(\"Model fitting complete.\")\n"
   ],
   "id": "c2d8ea62ee5debe0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# CATE Estimation\n",
    "\n",
    "After fitting the model, we can estimate the Conditional Average Treatment Effect (CATE) for each individual in our dataset. The CATE represents how much the treatment is expected to affect the outcome for an individual with specific characteristics.\n",
    "\n",
    "The CATE estimation process involves:\n",
    "1. Predicting treatment effects using the treatment group model\n",
    "2. Predicting treatment effects using the control group model\n",
    "3. Averaging the two predictions to get the final CATE estimate\n",
    "\n",
    "This gives us an estimate of the treatment effect for each individual, conditional on their covariates.\n",
    "</div>\n"
   ],
   "id": "e0764d21c06ab9a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T02:39:16.507410Z",
     "start_time": "2025-06-15T02:39:16.481449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate synthetic data with heterogeneous treatment effects if not already defined\n",
    "if 'features' not in globals():\n",
    "    # Create an instance of synthetic_data_for_cate with model2\n",
    "    data_generator = synthetic_data_for_cate(model_type='model2')\n",
    "\n",
    "    # Generate synthetic data\n",
    "    features, treatment_vector, outcomes = data_generator.get_synthetic_data()\n",
    "    print(f\"Generated data with {features.shape[0]} samples and {features.shape[1]} features\")\n",
    "    print(f\"Treatment assignment rate: {treatment_vector.mean():.2f}\")\n",
    "    print(f\"Outcome mean: {outcomes.mean():.2f}\")\n",
    "else:\n",
    "    # If features already exist, create a data generator to calculate true CATE\n",
    "    data_generator = synthetic_data_for_cate(model_type='model2')\n",
    "\n",
    "# Estimate treatment effects (CATE)\n",
    "cate = xl.predict(X=features)\n",
    "\n",
    "# Print basic statistics about the estimated CATE\n",
    "print(f\"CATE Statistics:\")\n",
    "print(f\"  Mean: {cate.mean():.4f}\")\n",
    "print(f\"  Std Dev: {cate.std():.4f}\")\n",
    "print(f\"  Min: {cate.min():.4f}\")\n",
    "print(f\"  Max: {cate.max():.4f}\")\n"
   ],
   "id": "d0b95cb124db83b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# CATE Distribution Visualization\n",
    "\n",
    "Visualizing the distribution of estimated treatment effects helps us understand the heterogeneity in treatment effects across the population. This can reveal:\n",
    "\n",
    "1. **Average Effect**: The center of the distribution shows the average treatment effect\n",
    "2. **Effect Heterogeneity**: The spread of the distribution shows how much treatment effects vary\n",
    "3. **Subgroups**: Multiple peaks might indicate distinct subgroups with different responses\n",
    "4. **Negative/Positive Effects**: The proportion of individuals with negative vs. positive effects\n",
    "\n",
    "A narrow distribution suggests homogeneous treatment effects, while a wide distribution suggests high heterogeneity. Skewness in the distribution might indicate that certain types of individuals benefit more or less from the treatment.\n",
    "</div>\n"
   ],
   "id": "69952eeca7765778"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T02:39:17.496422Z",
     "start_time": "2025-06-15T02:39:16.519816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate true treatment effects using the data generator\n",
    "# Generate synthetic data with heterogeneous treatment effects if not already defined\n",
    "if 'features' not in globals():\n",
    "    # Create an instance of synthetic_data_for_cate with model2\n",
    "    data_generator = synthetic_data_for_cate(model_type='model2')\n",
    "\n",
    "    # Generate synthetic data\n",
    "    features, treatment_vector, outcomes = data_generator.get_synthetic_data()\n",
    "    print(f\"Generated data with {features.shape[0]} samples and {features.shape[1]} features\")\n",
    "    print(f\"Treatment assignment rate: {treatment_vector.mean():.2f}\")\n",
    "    print(f\"Outcome mean: {outcomes.mean():.2f}\")\n",
    "else:\n",
    "    # If features already exist, create a data generator to calculate true CATE\n",
    "    data_generator = synthetic_data_for_cate(model_type='model2')\n",
    "\n",
    "# Calculate true treatment effects using the data generator\n",
    "true_cate = data_generator.get_true_cate(features)\n",
    "\n",
    "# Separate treated and control groups\n",
    "treated_indices = treatment_vector == 1\n",
    "control_indices = treatment_vector == 0\n",
    "\n",
    "# Create DataFrames for each group\n",
    "import pandas as pd\n",
    "\n",
    "treated_df = pd.DataFrame({\n",
    "    'Estimated CATE': cate[treated_indices],\n",
    "    'True CATE': true_cate[treated_indices]\n",
    "})\n",
    "\n",
    "control_df = pd.DataFrame({\n",
    "    'Estimated CATE': cate[control_indices],\n",
    "    'True CATE': true_cate[control_indices]\n",
    "})\n",
    "\n",
    "# Create images directory if it doesn't exist\n",
    "import os\n",
    "\n",
    "os.makedirs('images', exist_ok=True)\n",
    "\n",
    "# Plot for Treatment Group\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Plot both distributions with KDE\n",
    "sns.histplot(data=treated_df['Estimated CATE'], kde=True, alpha=0.6, bins=30)\n",
    "\n",
    "# Add vertical lines for mean values\n",
    "plt.axvline(x=treated_df['Estimated CATE'].mean(), color='blue', linestyle='--', linewidth=2,\n",
    "            label=f'Mean Estimated CATE: {treated_df[\"Estimated CATE\"].mean():.4f}')\n",
    "plt.axvline(x=treated_df['True CATE'].mean(), color='orange', linestyle='--', linewidth=2,\n",
    "            label=f'Mean True CATE: {treated_df[\"True CATE\"].mean():.4f}')\n",
    "\n",
    "# Add vertical line at zero (no effect)\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=1,\n",
    "            label='No Effect')\n",
    "\n",
    "# Add annotations\n",
    "plt.title('Distribution of True vs Estimated CATE - Treatment Group', fontsize=14)\n",
    "plt.xlabel('Treatment Effect', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Show percentage of positive and negative effects for estimated CATE\n",
    "est_pos_pct = (treated_df['Estimated CATE'] > 0).mean() * 100\n",
    "est_neg_pct = (treated_df['Estimated CATE'] < 0).mean() * 100\n",
    "plt.annotate(f'Estimated Positive Effects: {est_pos_pct:.1f}%',\n",
    "             xy=(0.68, 0.90), xycoords='axes fraction', fontsize=11)\n",
    "plt.annotate(f'Estimated Negative Effects: {est_neg_pct:.1f}%',\n",
    "             xy=(0.68, 0.85), xycoords='axes fraction', fontsize=11)\n",
    "\n",
    "# Show percentage of positive and negative effects for true CATE\n",
    "true_pos_pct = (treated_df['True CATE'] > 0).mean() * 100\n",
    "true_neg_pct = (treated_df['True CATE'] < 0).mean() * 100\n",
    "plt.annotate(f'True Positive Effects: {true_pos_pct:.1f}%',\n",
    "             xy=(0.68, 0.80), xycoords='axes fraction', fontsize=11)\n",
    "plt.annotate(f'True Negative Effects: {true_neg_pct:.1f}%',\n",
    "             xy=(0.68, 0.75), xycoords='axes fraction', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and display plot\n",
    "plt.savefig('images/x_learner_cate_distribution_treatment.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Treatment group CATE distribution plot saved to images/x_learner_cate_distribution_treatment.png\")\n",
    "plt.show()\n",
    "\n",
    "# Plot for Control Group\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Plot both distributions with KDE\n",
    "sns.histplot(data=control_df['Estimated CATE'], kde=True, alpha=0.6, bins=30)\n",
    "\n",
    "# Add vertical lines for mean values\n",
    "plt.axvline(x=control_df['Estimated CATE'].mean(), color='blue', linestyle='--', linewidth=2,\n",
    "            label=f'Mean Estimated CATE: {control_df[\"Estimated CATE\"].mean():.4f}')\n",
    "plt.axvline(x=control_df['True CATE'].mean(), color='orange', linestyle='--', linewidth=2,\n",
    "            label=f'Mean True CATE: {control_df[\"True CATE\"].mean():.4f}')\n",
    "\n",
    "# Add vertical line at zero (no effect)\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=1,\n",
    "            label='No Effect')\n",
    "\n",
    "# Add annotations\n",
    "plt.title('Distribution of True vs Estimated CATE - Control Group', fontsize=14)\n",
    "plt.xlabel('Treatment Effect', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Show percentage of positive and negative effects for estimated CATE\n",
    "est_pos_pct = (control_df['Estimated CATE'] > 0).mean() * 100\n",
    "est_neg_pct = (control_df['Estimated CATE'] < 0).mean() * 100\n",
    "plt.annotate(f'Estimated Positive Effects: {est_pos_pct:.1f}%',\n",
    "             xy=(0.68, 0.90), xycoords='axes fraction', fontsize=11)\n",
    "plt.annotate(f'Estimated Negative Effects: {est_neg_pct:.1f}%',\n",
    "             xy=(0.68, 0.85), xycoords='axes fraction', fontsize=11)\n",
    "\n",
    "# Show percentage of positive and negative effects for true CATE\n",
    "true_pos_pct = (control_df['True CATE'] > 0).mean() * 100\n",
    "true_neg_pct = (control_df['True CATE'] < 0).mean() * 100\n",
    "plt.annotate(f'True Positive Effects: {true_pos_pct:.1f}%',\n",
    "             xy=(0.68, 0.80), xycoords='axes fraction', fontsize=11)\n",
    "plt.annotate(f'True Negative Effects: {true_neg_pct:.1f}%',\n",
    "             xy=(0.68, 0.75), xycoords='axes fraction', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and display plot\n",
    "plt.savefig('images/x_learner_cate_distribution_control.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Control group CATE distribution plot saved to images/x_learner_cate_distribution_control.png\")\n",
    "plt.show()\n",
    "\n",
    "# Combined plot (original)\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Create a DataFrame for easier plotting with seaborn\n",
    "cate_df = pd.DataFrame({\n",
    "    'Estimated CATE': cate,\n",
    "    'True CATE': true_cate\n",
    "})\n",
    "\n",
    "# Plot both distributions with KDE\n",
    "sns.histplot(data=cate_df['Estimated CATE'], kde=True, alpha=0.6, bins=30)\n",
    "\n",
    "# Add vertical lines for mean values\n",
    "plt.axvline(x=cate.mean(), color='blue', linestyle='--', linewidth=2,\n",
    "            label=f'Mean Estimated CATE: {cate.mean():.4f}')\n",
    "plt.axvline(x=true_cate.mean(), color='orange', linestyle='--', linewidth=2,\n",
    "            label=f'Mean True CATE: {true_cate.mean():.4f}')\n",
    "\n",
    "# Add vertical line at zero (no effect)\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=1,\n",
    "            label='No Effect')\n",
    "\n",
    "# Add annotations\n",
    "plt.title('Distribution of True vs Estimated CATE - All Groups', fontsize=14)\n",
    "plt.xlabel('Treatment Effect', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Show percentage of positive and negative effects for estimated CATE\n",
    "est_pos_pct = (cate > 0).mean() * 100\n",
    "est_neg_pct = (cate < 0).mean() * 100\n",
    "plt.annotate(f'Estimated Positive Effects: {est_pos_pct:.1f}%',\n",
    "             xy=(0.68, 0.90), xycoords='axes fraction', fontsize=11)\n",
    "plt.annotate(f'Estimated Negative Effects: {est_neg_pct:.1f}%',\n",
    "             xy=(0.68, 0.85), xycoords='axes fraction', fontsize=11)\n",
    "\n",
    "# Show percentage of positive and negative effects for true CATE\n",
    "true_pos_pct = (true_cate > 0).mean() * 100\n",
    "true_neg_pct = (true_cate < 0).mean() * 100\n",
    "plt.annotate(f'True Positive Effects: {true_pos_pct:.1f}%',\n",
    "             xy=(0.68, 0.80), xycoords='axes fraction', fontsize=11)\n",
    "plt.annotate(f'True Negative Effects: {true_neg_pct:.1f}%',\n",
    "             xy=(0.68, 0.75), xycoords='axes fraction', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and display plot\n",
    "plt.savefig('images/x_learner_cate_distribution.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Combined CATE distribution plot saved to images/x_learner_cate_distribution.png\")\n",
    "plt.show()\n"
   ],
   "id": "d18ecbd58402164a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# Overlaid CATE Distributions: Estimated vs. True\n",
    "\n",
    "To better compare the estimated and true CATE distributions, we can overlay them on the same plot using different colors. This visualization allows us to:\n",
    "\n",
    "1. **Directly Compare Shapes**: See how closely the estimated distribution matches the true distribution\n",
    "2. **Identify Discrepancies**: Spot areas where the model over- or under-estimates treatment effects\n",
    "3. **Assess Heterogeneity Capture**: Determine if the model captures the true heterogeneity in treatment effects\n",
    "4. **Evaluate Peaks and Modes**: Compare the peaks and modes of both distributions\n",
    "\n",
    "The plot below shows both distributions with different colors, allowing for a direct visual comparison of their shapes, centers, and spreads.\n",
    "</div>\n"
   ],
   "id": "871c4621700e80ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T02:39:17.864411Z",
     "start_time": "2025-06-15T02:39:17.514319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a plot that overlays both the estimated and true CATE distributions\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Plot both distributions with KDE using different colors and line styles\n",
    "sns.kdeplot(data=cate_df, x='Estimated CATE', color='blue', fill=False, linewidth=2.5, linestyle='-',\n",
    "            label=f'Estimated CATE (Mean: {cate.mean():.4f})')\n",
    "sns.kdeplot(data=cate_df, x='True CATE', color='red', fill=False, linewidth=2.5, linestyle='--',\n",
    "            label=f'True CATE (Mean: {true_cate.mean():.4f})')\n",
    "\n",
    "# Add vertical lines for mean values\n",
    "plt.axvline(x=cate.mean(), color='blue', linestyle='-', linewidth=2)\n",
    "plt.axvline(x=true_cate.mean(), color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "# Add vertical line at zero (no effect)\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=1, label='No Effect')\n",
    "\n",
    "# Add annotations\n",
    "plt.title('Comparison of Estimated vs. True CATE Distributions', fontsize=14)\n",
    "plt.xlabel('Treatment Effect', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Calculate and display statistics\n",
    "est_std = cate.std()\n",
    "true_std = true_cate.std()\n",
    "\n",
    "# Calculate correlation and mean absolute error\n",
    "correlation = np.corrcoef(true_cate, cate)[0, 1]\n",
    "mae = np.mean(np.abs(true_cate - cate))\n",
    "\n",
    "# Safely calculate KL divergence approximation to avoid division by zero and log of negative values\n",
    "# Only consider positive values and avoid division by zero\n",
    "valid_indices = (cate > 0) & (true_cate > 0)\n",
    "if np.any(valid_indices):\n",
    "    kl_div = np.sum(cate[valid_indices] * np.log(cate[valid_indices] / true_cate[valid_indices]))\n",
    "else:\n",
    "    kl_div = np.nan\n",
    "\n",
    "# Add statistics annotations\n",
    "plt.annotate(f'Estimated CATE Std: {est_std:.4f}', xy=(0.05, 0.95), xycoords='axes fraction', fontsize=10)\n",
    "plt.annotate(f'True CATE Std: {true_std:.4f}', xy=(0.05, 0.90), xycoords='axes fraction', fontsize=10)\n",
    "plt.annotate(f'Mean Absolute Error: {mae:.4f}', xy=(0.05, 0.85), xycoords='axes fraction', fontsize=10)\n",
    "plt.annotate(f'Correlation: {correlation:.4f}', xy=(0.05, 0.80), xycoords='axes fraction', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and display plot\n",
    "plt.savefig('images/x_learner_cate_distributions_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"CATE distributions comparison plot saved to images/x_learner_cate_distributions_comparison.png\")\n",
    "plt.show()\n"
   ],
   "id": "d18e1bf9eb134b79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# CATE Accuracy Evaluation: Predicted vs. Actual Treatment Effects\n",
    "\n",
    "To evaluate the accuracy of our X-Learner model, we can compare the predicted CATE values with the actual treatment effects. This comparison helps us:\n",
    "\n",
    "1. **Assess Model Accuracy**: How well does the model recover the true treatment effects?\n",
    "2. **Identify Patterns in Errors**: Are there systematic biases in the predictions?\n",
    "3. **Compare Treatment Groups**: Do predictions differ in accuracy between treated and control groups?\n",
    "4. **Detect Outliers**: Are there individuals for whom the model predictions are particularly inaccurate?\n",
    "\n",
    "The scatter plot below shows:\n",
    "- Predicted CATE values on the y-axis\n",
    "- True treatment effects on the x-axis\n",
    "- Different symbols for treated and control groups\n",
    "- A diagonal line representing perfect prediction (y=x)\n",
    "\n",
    "Points close to the diagonal line indicate accurate predictions, while deviations suggest estimation errors.\n",
    "</div>\n"
   ],
   "id": "a51a754abde4303e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T02:39:18.218411Z",
     "start_time": "2025-06-15T02:39:17.880831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We already calculated the true CATE earlier, so we'll use that\n",
    "\n",
    "# Create a scatter plot of predicted vs. true treatment effects\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Separate treated and control groups for different markers\n",
    "treated_indices = treatment_vector == 1\n",
    "control_indices = treatment_vector == 0\n",
    "\n",
    "# Plot treated group with one marker\n",
    "plt.scatter(true_cate[treated_indices], cate[treated_indices], \n",
    "            marker='^', color='red', alpha=0.6, label='Treated Group')\n",
    "\n",
    "# Plot control group with another marker\n",
    "plt.scatter(true_cate[control_indices], cate[control_indices], \n",
    "            marker='o', color='blue', alpha=0.6, label='Control Group')\n",
    "\n",
    "# Add diagonal line (perfect prediction)\n",
    "min_val = min(true_cate.min(), cate.min())\n",
    "max_val = max(true_cate.max(), cate.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'k--', label='Perfect Prediction')\n",
    "\n",
    "# Calculate and display correlation coefficient\n",
    "# Note: correlation is already calculated in the previous cell\n",
    "plt.annotate(f'Correlation: {correlation:.4f}', \n",
    "             xy=(0.05, 0.95), xycoords='axes fraction', fontsize=12)\n",
    "\n",
    "# Calculate and display mean absolute error\n",
    "# Note: mae is already calculated in the previous cell\n",
    "plt.annotate(f'Mean Absolute Error: {mae:.4f}', \n",
    "             xy=(0.05, 0.90), xycoords='axes fraction', fontsize=12)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Predicted vs. Actual Treatment Effects', fontsize=14)\n",
    "plt.xlabel('Actual Treatment Effect', fontsize=12)\n",
    "plt.ylabel('Predicted Treatment Effect (CATE)', fontsize=12)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig('images/x_learner_cate_accuracy_evaluation.png', dpi=300, bbox_inches='tight')\n",
    "print(\"CATE accuracy evaluation plot saved to images/x_learner_cate_accuracy_evaluation.png\")\n",
    "\n",
    "plt.show()\n"
   ],
   "id": "b25717eb572ea5b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# Comparison of X-Learner Results with S-Learner and T-Learner\n",
    "\n",
    "Examining the CATE distribution and accuracy evaluation results from the X-Learner, we can observe several similarities with the S-Learner and T-Learner approaches:\n",
    "\n",
    "## CATE Distribution Similarities\n",
    "\n",
    "1. **Distribution Shape**: The X-Learner produces a CATE distribution with a similar bell-shaped curve to both S-Learner and T-Learner, indicating comparable heterogeneity capture across all three methods.\n",
    "\n",
    "2. **Mean CATE Values**: All three learners estimate mean CATE values that are close to the true mean, with similar slight deviations from the ground truth.\n",
    "\n",
    "3. **Positive/Negative Effect Proportions**: The proportion of positive vs. negative treatment effects is consistent across all three learners, suggesting they identify similar subpopulations that benefit or don't benefit from treatment.\n",
    "\n",
    "4. **Spread of Distribution**: The standard deviation of estimated CATE values is comparable across all three approaches, indicating similar levels of captured effect heterogeneity.\n",
    "\n",
    "## CATE Accuracy Evaluation Similarities\n",
    "\n",
    "1. **Correlation with True Effects**: The X-Learner achieves a correlation coefficient with true effects that is in the same range as the S-Learner and T-Learner, suggesting similar predictive performance.\n",
    "\n",
    "2. **Mean Absolute Error**: The MAE values are comparable across all three methods, indicating similar levels of estimation accuracy.\n",
    "\n",
    "3. **Prediction Patterns**: All three learners show similar patterns in the scatter plots of predicted vs. actual treatment effects, with comparable dispersion around the perfect prediction line.\n",
    "\n",
    "4. **Treatment/Control Group Differences**: The differences in prediction accuracy between treated and control groups follow similar patterns across all three methods.\n",
    "\n",
    "These similarities suggest that for this particular dataset and problem setting, the choice between X-Learner, S-Learner, and T-Learner may not dramatically impact the quality of CATE estimation. However, the X-Learner might still be preferred in scenarios with imbalanced treatment groups due to its theoretical advantages in such settings.\n",
    "\n",
    "</div>\n"
   ],
   "id": "7549e4c65b39f658"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}