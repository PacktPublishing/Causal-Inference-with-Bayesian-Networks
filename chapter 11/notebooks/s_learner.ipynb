{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# S-Learner for Conditional Average Treatment Effect (CATE) Estimation\n",
    "\n",
    "This notebook demonstrates the use of S-Learner for estimating heterogeneous treatment effects. \n",
    "\n",
    "## What is S-Learner?\n",
    "\n",
    "S-Learner (Single-Learner) is a meta-learner approach for estimating Conditional Average Treatment Effects (CATE). The key characteristics of S-Learner are:\n",
    "\n",
    "1. **Single Model Approach**: Uses a single model for both treatment and control groups\n",
    "2. **Treatment as Feature**: Includes treatment assignment as a feature in the model\n",
    "3. **Simplicity**: Simpler implementation compared to other meta-learners\n",
    "4. **Flexible Base Learners**: Can use any regression model that follows scikit-learn's API\n",
    "5. **Interaction Modeling**: Implicitly models interactions between treatment and covariates\n",
    "\n",
    "## How S-Learner Works\n",
    "\n",
    "The S-Learner approach follows these steps:\n",
    "1. Combine treatment indicator with features into a single feature matrix\n",
    "2. Train a single model to predict outcomes using this combined feature matrix\n",
    "3. Estimate CATE by predicting outcomes with treatment set to 1 and 0, then taking the difference\n",
    "\n",
    "The main advantage of S-Learner is its simplicity and ability to handle small sample sizes. However, it may not perform as well as other meta-learners when treatment effects are highly heterogeneous or when propensity scores vary significantly across the population.\n",
    "</div>\n"
   ],
   "id": "f312df28000ddf5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# Library Imports\n",
    "\n",
    "We import the necessary libraries for this demonstration:\n",
    "\n",
    "- **synthetic_data_for_cate**: Custom module for generating synthetic data with enhanced heterogeneity for treatment effects\n",
    "- **SLearner**: Our implementation of the S-Learner meta-learner\n",
    "- **sklearn models**: Various regression models to use as base learners\n",
    "- **matplotlib/seaborn**: For visualization\n",
    "- **numpy**: For numerical operations\n",
    "\n",
    "We also attempt to import optional dependencies (LightGBM and XGBoost) which provide additional base learners.\n",
    "</div>\n"
   ],
   "id": "513e629d1b198279"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T23:44:30.684568Z",
     "start_time": "2025-06-24T23:44:28.053569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "from synthetic_data.synthetic_data_for_cate_class import synthetic_data_for_cate\n",
    "# Force reload of the s_learner module to ensure we're using the latest version\n",
    "import metalearners.s_learner\n",
    "importlib.reload(metalearners.s_learner)\n",
    "from metalearners.s_learner import SLearner\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Set plot style\n",
    "try:\n",
    "    # For newer matplotlib versions (>=3.6)\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "except ValueError:\n",
    "    # For older matplotlib versions\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "# Try to import optional dependencies\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "    LIGHTGBM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LIGHTGBM_AVAILABLE = False\n",
    "    print(\"LightGBM not available. Some examples will be skipped.\")\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"XGBoost not available. Some examples will be skipped.\")\n"
   ],
   "id": "a9e1e86a9e7fda45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# Note on Dependencies\n",
    "\n",
    "This notebook requires the following packages:\n",
    "- numpy, matplotlib, seaborn: For data manipulation and visualization\n",
    "- scikit-learn: For machine learning models\n",
    "- lightgbm, xgboost (optional): For gradient boosting models\n",
    "\n",
    "The notebook also uses local packages:\n",
    "- synthetic_data.synthetic_data_for_cate: For generating synthetic data with enhanced heterogeneity\n",
    "- metalearners.s_learner: For the SLearner implementation\n",
    "\n",
    "Make sure you have installed all required dependencies before running this notebook.\n",
    "</div>\n"
   ],
   "id": "738b2a00e2e51739"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# Synthetic Data Generation\n",
    "\n",
    "We generate synthetic data with known heterogeneous treatment effects using the `synthetic_data_for_cate` class. This function creates:\n",
    "\n",
    "- A feature matrix with 5 covariates (by default)\n",
    "- A binary treatment indicator (1=treated, 0=control)\n",
    "- An outcome variable that depends on both covariates and treatment\n",
    "\n",
    "The data generation process includes:\n",
    "- Non-linear confounding (treatment assignment depends on X1 and X2)\n",
    "- Heterogeneous treatment effects (effects vary based on all covariates)\n",
    "- Non-linear baseline effects (outcome depends non-linearly on covariates)\n",
    "- Heteroskedastic noise (noise level varies with X1)\n",
    "\n",
    "This synthetic data allows us to evaluate the performance of different CATE estimation methods, as we know the true treatment effects.\n",
    "</div>\n"
   ],
   "id": "5d718657c9bb22cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T23:44:30.734094Z",
     "start_time": "2025-06-24T23:44:30.698345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create an instance of synthetic_data_for_cate with model2\n",
    "data_generator = synthetic_data_for_cate(model_type='model2')\n",
    "\n",
    "# Generate synthetic data with heterogeneous treatment effects\n",
    "features, treatment_vector, outcomes = data_generator.get_synthetic_data()\n",
    "\n",
    "# Print basic information about the generated data\n",
    "print(f\"Generated data with {features.shape[0]} samples and {features.shape[1]} features\")\n",
    "print(f\"Treatment assignment rate: {treatment_vector.mean():.2f}\")\n",
    "print(f\"Outcome mean: {outcomes.mean():.2f}\")\n"
   ],
   "id": "f30d44bfa8db5366",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# Model Initialization and Fitting\n",
    "\n",
    "We initialize several S-Learner models with different base learners:\n",
    "\n",
    "1. **Random Forest**: A non-parametric model that can capture complex non-linear relationships\n",
    "2. **Linear Regression**: A simple parametric model that assumes linear relationships\n",
    "3. **Gradient Boosting**: An ensemble method that builds trees sequentially to correct errors\n",
    "4. **LightGBM** (if available): A gradient boosting framework that uses tree-based learning\n",
    "5. **XGBoost** (if available): Another gradient boosting framework with different implementation\n",
    "\n",
    "Each model has different strengths and weaknesses for CATE estimation. For this demonstration, we'll use the Random Forest-based S-Learner as our primary model.\n",
    "\n",
    "The fitting process involves:\n",
    "1. Combining treatment indicator with features\n",
    "2. Training a single model on this combined feature matrix\n",
    "3. Using the model to predict outcomes under different treatment conditions\n",
    "</div>\n"
   ],
   "id": "c0e13867908b29d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T23:44:31.627716Z",
     "start_time": "2025-06-24T23:44:31.301608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize S-Learner with different base models\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "linear_model = LinearRegression()\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create S-Learner instances with different models\n",
    "s_learner_rf = SLearner(rf_model)\n",
    "s_learner_linear = SLearner(linear_model)\n",
    "s_learner_gb = SLearner(gb_model)\n",
    "\n",
    "# Create LightGBM model if available\n",
    "if 'LIGHTGBM_AVAILABLE' in globals() and LIGHTGBM_AVAILABLE:\n",
    "    lgbm_model = LGBMRegressor(random_state=42)\n",
    "    s_learner_lgbm = SLearner(lgbm_model)\n",
    "    # Uncomment to use LightGBM model\n",
    "    # sl = s_learner_lgbm\n",
    "\n",
    "# Create XGBoost model if available\n",
    "if 'XGBOOST_AVAILABLE' in globals() and XGBOOST_AVAILABLE:\n",
    "    xgb_model = XGBRegressor(random_state=42)\n",
    "    s_learner_xgb = SLearner(xgb_model)\n",
    "    # Uncomment to use XGBoost model\n",
    "    # sl = s_learner_xgb\n",
    "\n",
    "# Select Random Forest as our primary model\n",
    "sl = s_learner_rf\n",
    "\n",
    "# Fit the model\n",
    "print(\"Fitting S-Learner with Random Forest...\")\n",
    "sl.fit(\n",
    "    X=features,             # Feature matrix\n",
    "    t=treatment_vector,     # Treatment assignments (0/1)\n",
    "    y=outcomes              # Observed outcomes\n",
    ")\n",
    "print(\"Model fitting complete.\")\n"
   ],
   "id": "347f8e86f4448dd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:59:14.260743Z",
     "start_time": "2025-06-17T08:59:13.891474Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# CATE Estimation\n",
    "\n",
    "After fitting the model, we can estimate the Conditional Average Treatment Effect (CATE) for each individual in our dataset. The CATE represents how much the treatment is expected to affect the outcome for an individual with specific characteristics.\n",
    "\n",
    "The CATE estimation process for S-Learner involves:\n",
    "1. Predicting outcomes with treatment set to 1 for all individuals\n",
    "2. Predicting outcomes with treatment set to 0 for all individuals\n",
    "3. Taking the difference between these predictions to get the CATE\n",
    "\n",
    "This gives us an estimate of the treatment effect for each individual, conditional on their covariates.\n",
    "</div>\n"
   ],
   "id": "a305e22d22ac349f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T23:44:31.679917Z",
     "start_time": "2025-06-24T23:44:31.649942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Estimate treatment effects (CATE)\n",
    "cate = sl.effect(X=features)\n",
    "\n",
    "# Print basic statistics about the estimated CATE\n",
    "print(f\"CATE Statistics:\")\n",
    "print(f\"  Mean: {cate.mean():.4f}\")\n",
    "print(f\"  Std Dev: {cate.std():.4f}\")\n",
    "print(f\"  Min: {cate.min():.4f}\")\n",
    "print(f\"  Max: {cate.max():.4f}\")\n"
   ],
   "id": "5b83d3e98db1c393",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:59:14.323506Z",
     "start_time": "2025-06-17T08:59:14.283084Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# CATE Distribution Visualization\n",
    "\n",
    "Visualizing the distribution of estimated treatment effects helps us understand the heterogeneity in treatment effects across the population. This can reveal:\n",
    "\n",
    "1. **Average Effect**: The center of the distribution shows the average treatment effect\n",
    "2. **Effect Heterogeneity**: The spread of the distribution shows how much treatment effects vary\n",
    "3. **Subgroups**: Multiple peaks might indicate distinct subgroups with different responses\n",
    "4. **Negative/Positive Effects**: The proportion of individuals with negative vs. positive effects\n",
    "\n",
    "A narrow distribution suggests homogeneous treatment effects, while a wide distribution suggests high heterogeneity. Skewness in the distribution might indicate that certain types of individuals benefit more or less from the treatment.\n",
    "</div>\n"
   ],
   "id": "57101707609737d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T23:44:32.369581Z",
     "start_time": "2025-06-24T23:44:31.698048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate true treatment effects using the data generator\n",
    "true_cate = data_generator.get_true_cate(features)\n",
    "\n",
    "# Create a DataFrame for easier plotting with seaborn\n",
    "import pandas as pd\n",
    "cate_df = pd.DataFrame({\n",
    "    'Estimated CATE': cate,\n",
    "    'True CATE': true_cate\n",
    "})\n",
    "\n",
    "# Create images directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs('images', exist_ok=True)\n",
    "\n",
    "# Plot the distribution of estimated CATE\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Plot both distributions with KDE\n",
    "sns.histplot(data=cate_df['Estimated CATE'], kde=True, alpha=0.6, bins=30)\n",
    "\n",
    "# Add vertical lines for mean values\n",
    "plt.axvline(x=cate.mean(), color='blue', linestyle='--', linewidth=2,\n",
    "            label=f'Mean Estimated CATE: {cate.mean():.4f}')\n",
    "plt.axvline(x=true_cate.mean(), color='orange', linestyle='--', linewidth=2,\n",
    "            label=f'Mean True CATE: {true_cate.mean():.4f}')\n",
    "\n",
    "# Add vertical line at zero (no effect)\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=1,\n",
    "            label='No Effect')\n",
    "\n",
    "# Add annotations\n",
    "plt.title('Distribution of Estimated CATE - S-Learner', fontsize=14)\n",
    "plt.xlabel('Treatment Effect', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Show percentage of positive and negative effects for estimated CATE\n",
    "est_pos_pct = (cate > 0).mean() * 100\n",
    "est_neg_pct = (cate < 0).mean() * 100\n",
    "plt.annotate(f'Estimated Positive Effects: {est_pos_pct:.1f}%',\n",
    "             xy=(0.68, 0.90), xycoords='axes fraction', fontsize=11)\n",
    "plt.annotate(f'Estimated Negative Effects: {est_neg_pct:.1f}%',\n",
    "             xy=(0.68, 0.85), xycoords='axes fraction', fontsize=11)\n",
    "\n",
    "# Show percentage of positive and negative effects for true CATE\n",
    "true_pos_pct = (true_cate > 0).mean() * 100\n",
    "true_neg_pct = (true_cate < 0).mean() * 100\n",
    "plt.annotate(f'True Positive Effects: {true_pos_pct:.1f}%',\n",
    "             xy=(0.68, 0.80), xycoords='axes fraction', fontsize=11)\n",
    "plt.annotate(f'True Negative Effects: {true_neg_pct:.1f}%',\n",
    "             xy=(0.68, 0.75), xycoords='axes fraction', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and display plot\n",
    "plt.savefig('images/s_learner_cate_distribution.png', dpi=300, bbox_inches='tight')\n",
    "print(\"CATE distribution plot saved to images/s_learner_cate_distribution.png\")\n",
    "plt.show()\n"
   ],
   "id": "4a6becdb181a2ff2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:59:15.804842Z",
     "start_time": "2025-06-17T08:59:14.342701Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# Overlaid CATE Distributions: Estimated vs. True\n",
    "\n",
    "To better compare the estimated and true CATE distributions, we can overlay them on the same plot using different colors. This visualization allows us to:\n",
    "\n",
    "1. **Directly Compare Shapes**: See how closely the estimated distribution matches the true distribution\n",
    "2. **Identify Discrepancies**: Spot areas where the model over- or under-estimates treatment effects\n",
    "3. **Assess Heterogeneity Capture**: Determine if the model captures the true heterogeneity in treatment effects\n",
    "4. **Evaluate Peaks and Modes**: Compare the peaks and modes of both distributions\n",
    "\n",
    "The plot below shows both distributions with different colors, allowing for a direct visual comparison of their shapes, centers, and spreads.\n",
    "</div>\n"
   ],
   "id": "f978a212ea1591b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T23:44:32.696369Z",
     "start_time": "2025-06-24T23:44:32.389509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a plot that overlays both the estimated and true CATE distributions\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Plot both distributions with KDE using different colors and line styles\n",
    "sns.kdeplot(data=cate_df, x='Estimated CATE', color='blue', fill=False, linewidth=2.5, linestyle='-',\n",
    "            label=f'Estimated CATE (Mean: {cate.mean():.4f})')\n",
    "sns.kdeplot(data=cate_df, x='True CATE', color='red', fill=False, linewidth=2.5, linestyle='--',\n",
    "            label=f'True CATE (Mean: {true_cate.mean():.4f})')\n",
    "\n",
    "# Add vertical lines for mean values\n",
    "plt.axvline(x=cate.mean(), color='blue', linestyle='-', linewidth=2)\n",
    "plt.axvline(x=true_cate.mean(), color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "# Add vertical line at zero (no effect)\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=1, label='No Effect')\n",
    "\n",
    "# Add annotations\n",
    "plt.title('Comparison of Estimated vs. True CATE Distributions - S-Learner', fontsize=14)\n",
    "plt.xlabel('Treatment Effect', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Calculate and display statistics\n",
    "est_std = cate.std()\n",
    "true_std = true_cate.std()\n",
    "\n",
    "# Calculate correlation and mean absolute error\n",
    "correlation = np.corrcoef(true_cate, cate)[0, 1]\n",
    "mae = np.mean(np.abs(true_cate - cate))\n",
    "\n",
    "# Add statistics annotations\n",
    "plt.annotate(f'Estimated CATE Std: {est_std:.4f}', xy=(0.05, 0.95), xycoords='axes fraction', fontsize=10)\n",
    "plt.annotate(f'True CATE Std: {true_std:.4f}', xy=(0.05, 0.90), xycoords='axes fraction', fontsize=10)\n",
    "plt.annotate(f'Mean Absolute Error: {mae:.4f}', xy=(0.05, 0.85), xycoords='axes fraction', fontsize=10)\n",
    "plt.annotate(f'Correlation: {correlation:.4f}', xy=(0.05, 0.80), xycoords='axes fraction', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and display plot\n",
    "plt.savefig('images/s_learner_cate_distributions_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"CATE distributions comparison plot saved to images/s_learner_cate_distributions_comparison.png\")\n",
    "plt.show()\n"
   ],
   "id": "ab093788fc6ce301",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:59:16.140742Z",
     "start_time": "2025-06-17T08:59:15.829045Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# CATE Accuracy Evaluation: Predicted vs. Actual Treatment Effects\n",
    "\n",
    "To evaluate the accuracy of our S-Learner model, we can compare the predicted CATE values with the actual treatment effects. This comparison helps us:\n",
    "\n",
    "1. **Assess Model Accuracy**: How well does the model recover the true treatment effects?\n",
    "2. **Identify Patterns in Errors**: Are there systematic biases in the predictions?\n",
    "3. **Compare Treatment Groups**: Do predictions differ in accuracy between treated and control groups?\n",
    "4. **Detect Outliers**: Are there individuals for whom the model predictions are particularly inaccurate?\n",
    "\n",
    "The scatter plot below shows:\n",
    "- Predicted CATE values on the y-axis\n",
    "- True treatment effects on the x-axis\n",
    "- Different symbols for treated and control groups\n",
    "- A diagonal line representing perfect prediction (y=x)\n",
    "\n",
    "Points close to the diagonal line indicate accurate predictions, while deviations suggest estimation errors.\n",
    "</div>\n"
   ],
   "id": "15ff541a637834ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T23:44:33.057419Z",
     "start_time": "2025-06-24T23:44:32.722484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a scatter plot of predicted vs. true treatment effects\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Separate treated and control groups for different markers\n",
    "treated_indices = treatment_vector == 1\n",
    "control_indices = treatment_vector == 0\n",
    "\n",
    "# Plot treated group with one marker\n",
    "plt.scatter(true_cate[treated_indices], cate[treated_indices], \n",
    "            marker='^', color='red', alpha=0.6, label='Treated Group')\n",
    "\n",
    "# Plot control group with another marker\n",
    "plt.scatter(true_cate[control_indices], cate[control_indices], \n",
    "            marker='o', color='blue', alpha=0.6, label='Control Group')\n",
    "\n",
    "# Add diagonal line (perfect prediction)\n",
    "min_val = min(true_cate.min(), cate.min())\n",
    "max_val = max(true_cate.max(), cate.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'k--', label='Perfect Prediction')\n",
    "\n",
    "# Calculate and display correlation coefficient\n",
    "plt.annotate(f'Correlation: {correlation:.4f}', \n",
    "             xy=(0.05, 0.95), xycoords='axes fraction', fontsize=12)\n",
    "\n",
    "# Calculate and display mean absolute error\n",
    "plt.annotate(f'Mean Absolute Error: {mae:.4f}', \n",
    "             xy=(0.05, 0.90), xycoords='axes fraction', fontsize=12)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Predicted vs. Actual Treatment Effects - S-Learner', fontsize=14)\n",
    "plt.xlabel('Actual Treatment Effect', fontsize=12)\n",
    "plt.ylabel('Predicted Treatment Effect (CATE)', fontsize=12)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig('images/s_learner_cate_accuracy_evaluation.png', dpi=300, bbox_inches='tight')\n",
    "print(\"CATE accuracy evaluation plot saved to images/s_learner_cate_accuracy_evaluation.png\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "dd310c6caa194cc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 0.85em;\">\n",
    "\n",
    "# Scatter Plot Analysis: Discrete True CATE vs. Continuous Estimated CATE\n",
    "\n",
    "## Observation of Discrete vs. Continuous Values\n",
    "\n",
    "The scatter plot reveals an important characteristic of our data and model:\n",
    "\n",
    "- **True CATE Values (x-axis)**: Appear as discrete values, forming vertical clusters\n",
    "- **Estimated CATE Values (y-axis)**: Appear as continuous values, spread across a range from approximately -6 to +10\n",
    "\n",
    "This pattern occurs because:\n",
    "\n",
    "1. **True CATE Generation**: In model2, true CATE values are generated using threshold functions:\n",
    "   ```python\n",
    "   true_cate = (\n",
    "       4.0 * (features[:, 0] > 0.5) -  # +4.0 if X1 > 0.5\n",
    "       3.0 * (features[:, 1] > 0.7) +  # -3.0 if X2 > 0.7\n",
    "       5.0 * (features[:, 2] * features[:, 3] > 0.5) -  # +5.0 if X3*X4 > 0.5\n",
    "       2.0 * (features[:, 4] < 0.3)    # -2.0 if X5 < 0.3\n",
    "   )\n",
    "   ```\n",
    "\n",
    "   Each component is a binary condition (0 or 1) multiplied by a coefficient. With 4 binary conditions, there are 2\u2074 = 16 possible combinations, creating a discrete set of possible CATE values.\n",
    "\n",
    "2. **Estimated CATE Generation**: The S-Learner uses RandomForestRegressor, which produces continuous predictions by averaging the outputs of many decision trees, resulting in a continuous range of estimated values.\n",
    "\n",
    "## Addressing the Key Questions\n",
    "\n",
    "### 1. Model Accuracy Assessment\n",
    "\n",
    "- **Correlation**: 0.9133 - Indicates a very strong positive correlation between true and estimated CATE values\n",
    "- **Mean Absolute Error**: 0.8050 - Represents the average magnitude of errors\n",
    "- **Visual Assessment**: Points cluster around the diagonal line but with considerable spread, suggesting moderate accuracy\n",
    "\n",
    "The model captures the general direction of treatment effects (positive vs. negative) reasonably well, but struggles to precisely estimate the exact magnitude of effects. This is expected given the challenge of recovering discrete threshold-based effects using a continuous prediction model.\n",
    "\n",
    "### 2. Patterns in Errors\n",
    "\n",
    "Several systematic patterns are visible:\n",
    "\n",
    "- **Regression to the Mean**: Extreme true CATE values tend to have less extreme predictions, a common phenomenon in predictive modeling\n",
    "- **Horizontal Banding**: Predictions cluster around certain horizontal bands, suggesting the model is identifying some discrete effect levels but not capturing the full complexity\n",
    "- **Overestimation of Negative Effects**: The model tends to predict less negative values for the most negative true CATE values\n",
    "- **Underestimation of Positive Effects**: The highest true CATE values are often underestimated\n",
    "\n",
    "These patterns suggest the model is smoothing out the sharp threshold effects present in the true data generation process.\n",
    "\n",
    "### 3. Treatment Group Comparison\n",
    "\n",
    "Comparing the red triangles (treated group) and blue circles (control group):\n",
    "\n",
    "- **Distribution**: Both groups appear similarly distributed across the true CATE spectrum\n",
    "- **Accuracy**: There's no obvious difference in prediction accuracy between treated and control groups\n",
    "- **Density**: The treated group may have slightly more points in certain regions, reflecting the non-random treatment assignment in the data generation process\n",
    "\n",
    "The similar prediction accuracy across groups suggests the S-Learner is not biased toward either group, which is a positive finding for fairness in treatment effect estimation.\n",
    "\n",
    "### 4. Outlier Detection\n",
    "\n",
    "Several types of outliers are visible:\n",
    "\n",
    "- **Far from Diagonal**: Some points deviate significantly from the perfect prediction line\n",
    "- **Extreme Predictions**: A few points have estimated CATE values below -5 or above +8, which are more extreme than most predictions\n",
    "- **Misclassified Direction**: Some points with positive true CATE have negative estimated CATE and vice versa, representing qualitative errors in effect direction\n",
    "\n",
    "These outliers likely occur when:\n",
    "1. Multiple feature interactions create complex patterns that the model fails to capture\n",
    "2. Rare feature combinations appear in the data that weren't well-represented in the training process\n",
    "3. The inherent noise in the data generation process leads to challenging cases\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The S-Learner provides reasonable but imperfect estimates of the true CATE values. The discrete nature of the true effects presents a fundamental challenge for any continuous prediction model. While the model captures the general pattern of effects, it struggles with precise estimation of threshold-based effects. This highlights the importance of understanding the underlying data generation process when interpreting model predictions.\n",
    "\n",
    "</div>\n"
   ],
   "id": "26f5800aa55050c8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}